{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028f1144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 09:53:10.937541: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-02 09:53:16.069905: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 09:53:16.070201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 09:53:16.083454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-02 09:53:17.890833: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 09:53:34.344272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/cluster/home/taheeraa/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/cluster/home/taheeraa/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, Swinv2ForImageClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "import onnx\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd9394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_dir = os.path.join(project_dir, 'src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from utils import generate_class_weights, show_batch_images\n",
    "from data import ChestXray14HFDataset\n",
    "from trainers import MultiLabelLightningModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795136ff",
   "metadata": {},
   "source": [
    "## load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8813ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/cluster/home/taheeraa/datasets/chestxray-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5e7930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'Atelectasis': 0.06666666666666667, 'Cardiomegaly': 0.6968494101318529, 'Effusion': 3.3449700199866754, 'Infiltration': 0.6563995293502418, 'Mass': 0.41714855433698905, 'Nodule': 1.4048125349748182, 'Pneumonia': 1.2366502463054188, 'Pneumothorax': 6.52051948051948, 'Consolidation': 2.237433155080214, 'Edema': 2.024516129032258, 'Emphysema': 4.1494214876033055, 'Fibrosis': 4.01664, 'Pleural_Thickening': 4.63601108033241, 'Hernia': 2.6055007784120394}\n",
      "Train dataframe shape: (75312, 16) (1 size larger than expected due to 'Full Image Path')\n",
      "Train columns: Index(['Full Image Path', 'Image Filename', 'Atelectasis', 'Cardiomegaly',\n",
      "       'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
      "       'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
      "       'Pleural_Thickening', 'Hernia'],\n",
      "      dtype='object')\n",
      "Labels: ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
      "Number of labels: 14\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "    \"Atelectasis\", \n",
    "    \"Cardiomegaly\",\n",
    "    \"Effusion\", \n",
    "    \"Infiltration\", \n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",  \n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Hernia\"\n",
    "]\n",
    "file_path_train = data_path + '/train_official.txt'\n",
    "file_path_val = data_path + '/val_official.txt'\n",
    "file_path_test = data_path + '/test_official.txt'\n",
    "\n",
    "columns = ['Image Filename'] + labels\n",
    "\n",
    "df_train = pd.read_csv(file_path_train, sep='\\s+', names=columns)\n",
    "df_val = pd.read_csv(file_path_val, sep='\\s+', names=columns)\n",
    "df_test = pd.read_csv(file_path_test, sep='\\s+', names=columns)\n",
    "\n",
    "# Finding all image paths, and mapping them to the DataFrame\n",
    "subfolders = [f\"images_{i:03}/images\" for i in range(1, 13)]  # Generates 'images_001' to 'images_012'\n",
    "path_mapping = {}\n",
    "for subfolder in subfolders:\n",
    "    full_folder_path = os.path.join(data_path, subfolder)\n",
    "    for img_file in os.listdir(full_folder_path):\n",
    "        path_mapping[img_file] = os.path.join(full_folder_path, img_file)\n",
    "\n",
    "# Update the DataFrame using the mapping\n",
    "df_train['Full Image Path'] = df_train['Image Filename'].map(path_mapping)\n",
    "df_val['Full Image Path'] = df_val['Image Filename'].map(path_mapping)\n",
    "df_test['Full Image Path'] = df_test['Image Filename'].map(path_mapping)\n",
    "\n",
    "# Move 'Full Image Path' to the front of the DataFrame\n",
    "cols_train = ['Full Image Path'] + [col for col in df_train.columns if col != 'Full Image Path']\n",
    "cols_val = ['Full Image Path'] + [col for col in df_val.columns if col != 'Full Image Path']\n",
    "cols_test = ['Full Image Path'] + [col for col in df_test.columns if col != 'Full Image Path']\n",
    "df_train = df_train[cols_train]\n",
    "df_val = df_val[cols_val]\n",
    "df_test = df_test[cols_test]\n",
    "\n",
    "# Drop 'Image Filename' column\n",
    "train_df = df_train.drop(columns=['Image Filename'])\n",
    "val_df = df_val.drop(columns=['Image Filename'])\n",
    "test_df = df_test.drop(columns=['Image Filename'])\n",
    "\n",
    "# Create class weights\n",
    "df_train_calculate_weights = df_train.drop(columns=['Full Image Path']).to_numpy()\n",
    "class_weights_dict = generate_class_weights(df_train_calculate_weights, multi_class=False, one_hot_encoded=True)\n",
    "class_weights_list = [class_weights_dict[i] for i in class_weights_dict]\n",
    "class_weights_tensor = torch.tensor(class_weights_list, dtype=torch.float32)\n",
    "\n",
    "label_weights_dict = {labels[i]: class_weights_dict[i] for i in range(len(labels))}\n",
    "print(f\"Class weights: {label_weights_dict}\")\n",
    "\n",
    "print(f\"Train dataframe shape: {df_train.shape} (1 size larger than expected due to 'Full Image Path')\")\n",
    "print(f\"Train columns: {df_train.columns}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4b73c",
   "metadata": {},
   "source": [
    "## load dataset and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e244f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "num_workers = 4\n",
    "pin_memory = False\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1901e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=7),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6582849",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChestXray14HFDataset(\n",
    "    dataframe=train_df, transform=train_transforms)\n",
    "val_dataset = ChestXray14HFDataset(\n",
    "    dataframe=val_df, transform=val_transforms)\n",
    "test_dataset = ChestXray14HFDataset(\n",
    "    dataframe=test_df, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e050b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=pin_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448a4c7",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca0d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelInferenceModel(LightningModule):\n",
    "    def __init__(self, model, criterion, learning_rate, num_labels, img_size, labels):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_labels = num_labels\n",
    "        self.log_step_interval = 100\n",
    "        self.img_size = img_size\n",
    "        self.labels = labels\n",
    "\n",
    "        self.f1_score = MultilabelF1Score(num_labels=self.num_labels, threshold=0.5, average='macro')\n",
    "        self.f1_score_micro = MultilabelF1Score(num_labels=self.num_labels, threshold=0.5, average='micro')\n",
    "        self.auroc = AUROC(task=\"multilabel\", num_labels=self.num_labels, average=\"macro\")\n",
    "        self.auroc_classwise = AUROC(\n",
    "            task=\"multilabel\",\n",
    "            num_labels=self.num_labels,\n",
    "            average=None,\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        return self.model(pixel_values)\n",
    "\n",
    "    def step(self, batch):\n",
    "        pixel_values = batch['pixel_values']\n",
    "        labels = batch['labels']\n",
    "\n",
    "        logits = self.forward(pixel_values)\n",
    "\n",
    "        loss = self.criterion(logits, labels)\n",
    "        return loss, logits, labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, logits, labels = self.step(batch)\n",
    "        self.log('train_loss', loss, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        # Update metrics\n",
    "        f1 = self.f1_with_sigmoid(logits, labels)\n",
    "        f1_micro = self.f1_micro_with_sigmoid(logits, labels)\n",
    "        auroc = self.auroc_with_sigmoid(logits, labels)\n",
    "        auroc_classwise = self.auroc_classwise_with_sigmoid(logits, labels.type(torch.int32))\n",
    "\n",
    "        if batch_idx % self.log_step_interval == 0:\n",
    "            self.calc_classwise_auroc(auroc_classwise)\n",
    "            self.log('train_f1', f1, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('train_f1_micro', f1_micro, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('train_auroc', auroc, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('train_loss', loss, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        loss, logits, labels = self.step(batch)\n",
    "        f1 = self.f1_with_sigmoid(logits, labels)\n",
    "        f1_micro = self.f1_micro_with_sigmoid(logits, labels)\n",
    "        auroc = self.auroc_with_sigmoid(logits, labels)\n",
    "        auroc_classwise = self.auroc_classwise_with_sigmoid(logits, labels.type(torch.int32))\n",
    "\n",
    "        if batch_idx % self.log_step_interval == 0:\n",
    "            self.calc_classwise_auroc(auroc_classwise)\n",
    "            self.log('val_f1', f1, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_f1_micro', f1_micro, on_step=True,\n",
    "                        on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_auroc', auroc, on_step=True,\n",
    "                        on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_loss', loss, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def calc_classwise_auroc(self, auroc_classwise):\n",
    "        for label_name, score in zip(self.label_names, auroc_classwise):\n",
    "            self.log(f'train_auroc_{label_name}', score, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, logits, labels = self.step(batch)\n",
    "        f1 = self.f1_with_sigmoid(logits, labels)\n",
    "        f1_micro = self.f1_micro_with_sigmoid(logits, labels)\n",
    "        auroc = self.auroc_with_sigmoid(logits, labels)\n",
    "        auroc_classwise = self.auroc_classwise_with_sigmoid(logits, labels.type(torch.int32))\n",
    "\n",
    "        self.calc_classwise_auroc(auroc_classwise)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_f1', f1)\n",
    "        self.log('test_f1_micro', f1_micro)\n",
    "        self.log('test_auroc', auroc)\n",
    "\n",
    "        return {'test_loss': loss, 'test_f1': f1, 'test_f1_micro': f1_micro}\n",
    "\n",
    "    def on_test_end(self):\n",
    "        self.save_model()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer\n",
    "        scheduler = self.scheduler\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def save_model(self):\n",
    "        self.file_manager.logger.info(onnx.__version__)  # This will print the version of ONNX installe\n",
    "\n",
    "        self.to_onnx(f\"./test-model.onnx\", input_sample=torch.randn(1, 3, self.img_size, self.img_size))\n",
    "\n",
    "    def f1_with_sigmoid(self, logits, labels):\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return self.f1_score(preds, labels)\n",
    "\n",
    "    def f1_micro_with_sigmoid(self, logits, labels):\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return self.f1_score_micro(preds, labels)\n",
    "\n",
    "    def auroc_with_sigmoid(self, logits, labels):\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return self.auroc(preds, labels.type(torch.int32))\n",
    "\n",
    "    def auroc_classwise_with_sigmoid(self, logits, labels):\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return self.auroc_classwise(preds, labels.type(torch.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b8f3c",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f5f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file=\"/cluster/home/taheeraa/code/master-thesis/01-multi-label/checkpoints/DenseNet121_aug4_pretrain_WeightBelow1_1_0.829766922537.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "914b7ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: The model has 7794184 trainable parameters\n",
      "after: The model has 7370030 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, resnet34, alexnet, vit_b_16, densenet121, efficientnet_b1\n",
    "import torch.nn as nn\n",
    "\n",
    "def classifying_head(in_features: int, num_labels: int):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features=in_features, out_features=512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(in_features=512, out_features=256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.BatchNorm1d(num_features=256),\n",
    "        nn.Linear(256, num_labels),\n",
    "    )\n",
    "\n",
    "model = efficientnet_b1(weights=\"IMAGENET1K_V1\")\n",
    "#model = resnet50(weights='IMAGENET1K_V2')\n",
    "img_size = int(224) \n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Get the number of parameters\n",
    "num_params = count_parameters(model)\n",
    "print(f'before: The model has {num_params} trainable parameters')\n",
    "\n",
    "model.classifier = classifying_head(1408, 14)\n",
    "num_params = count_parameters(model)\n",
    "print(f'after: The model has {num_params} trainable parameters')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
