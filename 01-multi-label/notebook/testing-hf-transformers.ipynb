{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "028f1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Swinv2ForImageClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics import AUROC\n",
    "import torch\n",
    "import onnx\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cd9394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_dir = os.path.join(project_dir, 'src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from utils import generate_class_weights, show_batch_images\n",
    "from data import ChestXray14HFDataset\n",
    "from trainers import MultiLabelLightningModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795136ff",
   "metadata": {},
   "source": [
    "## load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad8813ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/cluster/home/taheeraa/datasets/chestxray-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de5e7930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'Atelectasis': 0.06666666666666667, 'Cardiomegaly': 0.6968494101318529, 'Effusion': 3.3449700199866754, 'Infiltration': 0.6563995293502418, 'Mass': 0.41714855433698905, 'Nodule': 1.4048125349748182, 'Pneumonia': 1.2366502463054188, 'Pneumothorax': 6.52051948051948, 'Consolidation': 2.237433155080214, 'Edema': 2.024516129032258, 'Emphysema': 4.1494214876033055, 'Fibrosis': 4.01664, 'Pleural_Thickening': 4.63601108033241, 'Hernia': 2.6055007784120394}\n",
      "Train dataframe shape: (75312, 16) (1 size larger than expected due to 'Full Image Path')\n",
      "Train columns: Index(['Full Image Path', 'Image Filename', 'Atelectasis', 'Cardiomegaly',\n",
      "       'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
      "       'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',\n",
      "       'Pleural_Thickening', 'Hernia'],\n",
      "      dtype='object')\n",
      "Labels: ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
      "Number of labels: 14\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "    \"Atelectasis\", \n",
    "    \"Cardiomegaly\",\n",
    "    \"Effusion\", \n",
    "    \"Infiltration\", \n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",  \n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Hernia\"\n",
    "]\n",
    "file_path_train = data_path + '/train_official.txt'\n",
    "file_path_val = data_path + '/val_official.txt'\n",
    "file_path_test = data_path + '/test_official.txt'\n",
    "\n",
    "columns = ['Image Filename'] + labels\n",
    "\n",
    "df_train = pd.read_csv(file_path_train, sep='\\s+', names=columns)\n",
    "df_val = pd.read_csv(file_path_val, sep='\\s+', names=columns)\n",
    "df_test = pd.read_csv(file_path_test, sep='\\s+', names=columns)\n",
    "\n",
    "# Finding all image paths, and mapping them to the DataFrame\n",
    "subfolders = [f\"images_{i:03}/images\" for i in range(1, 13)]  # Generates 'images_001' to 'images_012'\n",
    "path_mapping = {}\n",
    "for subfolder in subfolders:\n",
    "    full_folder_path = os.path.join(data_path, subfolder)\n",
    "    for img_file in os.listdir(full_folder_path):\n",
    "        path_mapping[img_file] = os.path.join(full_folder_path, img_file)\n",
    "\n",
    "# Update the DataFrame using the mapping\n",
    "df_train['Full Image Path'] = df_train['Image Filename'].map(path_mapping)\n",
    "df_val['Full Image Path'] = df_val['Image Filename'].map(path_mapping)\n",
    "df_test['Full Image Path'] = df_test['Image Filename'].map(path_mapping)\n",
    "\n",
    "# Move 'Full Image Path' to the front of the DataFrame\n",
    "cols_train = ['Full Image Path'] + [col for col in df_train.columns if col != 'Full Image Path']\n",
    "cols_val = ['Full Image Path'] + [col for col in df_val.columns if col != 'Full Image Path']\n",
    "cols_test = ['Full Image Path'] + [col for col in df_test.columns if col != 'Full Image Path']\n",
    "df_train = df_train[cols_train]\n",
    "df_val = df_val[cols_val]\n",
    "df_test = df_test[cols_test]\n",
    "\n",
    "# Drop 'Image Filename' column\n",
    "train_df = df_train.drop(columns=['Image Filename'])\n",
    "val_df = df_val.drop(columns=['Image Filename'])\n",
    "test_df = df_test.drop(columns=['Image Filename'])\n",
    "\n",
    "# Create class weights\n",
    "df_train_calculate_weights = df_train.drop(columns=['Full Image Path']).to_numpy()\n",
    "class_weights_dict = generate_class_weights(df_train_calculate_weights, multi_class=False, one_hot_encoded=True)\n",
    "class_weights_list = [class_weights_dict[i] for i in class_weights_dict]\n",
    "class_weights_tensor = torch.tensor(class_weights_list, dtype=torch.float32)\n",
    "\n",
    "label_weights_dict = {labels[i]: class_weights_dict[i] for i in range(len(labels))}\n",
    "print(f\"Class weights: {label_weights_dict}\")\n",
    "\n",
    "print(f\"Train dataframe shape: {df_train.shape} (1 size larger than expected due to 'Full Image Path')\")\n",
    "print(f\"Train columns: {df_train.columns}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Number of labels: {len(labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4b73c",
   "metadata": {},
   "source": [
    "## load dataset and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e244f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "num_workers = 4\n",
    "pin_memory = False\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1901e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=7),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6582849",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ChestXray14HFDataset(\n",
    "    dataframe=train_df, transform=train_transforms)\n",
    "val_dataset = ChestXray14HFDataset(\n",
    "    dataframe=val_df, transform=val_transforms)\n",
    "test_dataset = ChestXray14HFDataset(\n",
    "    dataframe=test_df, transform=val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4e050b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers, \n",
    "    pin_memory=pin_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448a4c7",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ca0d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "class MultiLabelLightningModule(LightningModule):\n",
    "    def __init__(self, model, criterion, learning_rate, num_labels, scheduler, optimizer):\n",
    "        super().__init__()\n",
    "        self.model_arg = \"swin\"\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_labels = num_labels\n",
    "        self.scheduler = scheduler\n",
    "        self.optimizer = optimizer\n",
    "        self.log_step_interval = 100\n",
    "\n",
    "        self.f1_score = MultilabelF1Score(\n",
    "            num_labels=self.num_labels, threshold=0.5, average='macro')\n",
    "\n",
    "        self.f1_score_micro = MultilabelF1Score(\n",
    "            num_labels=self.num_labels, threshold=0.5, average='micro')\n",
    "        \n",
    "        self.auroc = AUROC(\n",
    "            task=\"multilabel\",\n",
    "            num_labels=self.num_labels,\n",
    "            average=\"macro\",\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        return self.model(pixel_values)\n",
    "\n",
    "    def step(self, batch):\n",
    "        pixel_values = batch['pixel_values']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        if self.model_arg == 'swin':\n",
    "            logits = self.forward(pixel_values.logit)\n",
    "        else:\n",
    "            logits = self.forward(pixel_values)\n",
    "\n",
    "        loss = self.criterion(logits, labels)\n",
    "        return loss, logits, labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, logits, labels = self.step(batch)\n",
    "        self.log('train_loss', loss, on_step=True,\n",
    "                 on_epoch=True, prog_bar=True, logger=True)\n",
    "        # Update metrics\n",
    "        f1 = self.f1_with_sigmoid(logits, labels)\n",
    "        f1_micro = self.f1_micro_with_sigmoid(logits, labels)\n",
    "        auroc = self.auroc_with_sigmoid(logits, labels)\n",
    "\n",
    "        # Log metrics\n",
    "        if batch_idx % self.log_step_interval == 0:\n",
    "            self.log('train_f1', f1, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('train_f1_micro', f1_micro, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('train_auroc', auroc, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('train_loss', loss, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, logits, labels = self.step(batch)\n",
    "        f1 = self.f1_with_sigmoid(logits, labels)\n",
    "        f1_micro = self.f1_micro_with_sigmoid(logits, labels)\n",
    "        auroc = self.auroc_with_sigmoid(logits, labels)\n",
    "\n",
    "        if batch_idx % self.log_step_interval == 0:\n",
    "            self.log('val_f1', f1, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_f1_micro', f1_micro, on_step=True,\n",
    "                        on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_auroc', auroc, on_step=True,\n",
    "                        on_epoch=True, prog_bar=True, logger=True)\n",
    "            self.log('val_loss', loss, on_step=True,\n",
    "                     on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, logits, labels = self.step(batch)\n",
    "        f1 = self.f1_with_sigmoid(logits, labels)\n",
    "        f1_micro = self.f1_micro_with_sigmoid(logits, labels)\n",
    "        auroc = self.auroc_with_sigmoid(logits, labels)\n",
    "\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_f1', f1)\n",
    "        self.log('test_f1_micro', f1_micro)\n",
    "        self.log('test_auroc', auroc)\n",
    "\n",
    "        return {'test_loss': loss, 'test_f1': f1, 'test_f1_micro': f1_micro}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer], [self.scheduler]\n",
    "\n",
    "    def f1_with_sigmoid(self, logits, labels):\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return self.f1_score(preds, labels)\n",
    "\n",
    "    def f1_micro_with_sigmoid(self, logits, labels):\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return self.f1_score_micro(preds, labels)\n",
    "    \n",
    "    def auroc_with_sigmoid(self, logits, labels):\n",
    "        preds = torch.sigmoid(logits)\n",
    "        return self.auroc(preds, labels.type(torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "615135fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir=\"test\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_top_k=1, \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    min_delta=0.00,\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b8f3c",
   "metadata": {},
   "source": [
    "## set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04cd4d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-tiny-patch4-window8-256 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([14, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([14]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Swinv2ForImageClassification(\n",
       "  (swinv2): Swinv2Model(\n",
       "    (embeddings): Swinv2Embeddings(\n",
       "      (patch_embeddings): Swinv2PatchEmbeddings(\n",
       "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      )\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): Swinv2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (key): Linear(in_features=96, out_features=96, bias=False)\n",
       "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (key): Linear(in_features=192, out_features=192, bias=False)\n",
       "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-5): 6 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (key): Linear(in_features=384, out_features=384, bias=False)\n",
       "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (downsample): Swinv2PatchMerging(\n",
       "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Swinv2Stage(\n",
       "          (blocks): ModuleList(\n",
       "            (0-1): 2 x Swinv2Layer(\n",
       "              (attention): Swinv2Attention(\n",
       "                (self): Swinv2SelfAttention(\n",
       "                  (continuous_position_bias_mlp): Sequential(\n",
       "                    (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                    (1): ReLU(inplace=True)\n",
       "                    (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "                  )\n",
       "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): Swinv2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (drop_path): Swinv2DropPath(p=0.1)\n",
       "              (intermediate): Swinv2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): Swinv2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(self, model, criterion, learning_rate, num_labels, scheduler, optimizer):\n",
    "id2label = {id: label for id, label in enumerate(labels)}\n",
    "label2id = {label: id for id, label in id2label.items()}\n",
    "    \n",
    "model = Swinv2ForImageClassification.from_pretrained(\n",
    "    \"microsoft/swinv2-tiny-patch4-window8-256\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d77e1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "learning_rate = 0.0005\n",
    "num_labels = len(labels)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scheduler = {'scheduler': scheduler, 'monitor': 'val_loss'}\n",
    "\n",
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ede97b79",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1035869/1326150688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m pl_trainer = Trainer(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_connector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_DataConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         self._accelerator_connector = _AcceleratorConnector(\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mdevices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0maccelerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# 3. Instantiate ClusterEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mClusterEnvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_choose_and_init_cluster_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# 4. Instantiate Strategy - Part 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m_choose_and_init_cluster_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m         ):\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menv_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0menv_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_LIGHTNING_BAGUA_AVAILABLE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mlightning_bagua\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaguaEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, auto_requeue, requeue_signal)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequeue_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequeue_signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_srun_used\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_srun_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py\u001b[0m in \u001b[0;36m_validate_srun_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mntasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SLURM_NTASKS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mntasks\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"SLURM_NTASKS_PER_NODE\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;34mf\"You set `--ntasks={ntasks}` in your SLURM bash script, but this variable is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;34mf\" HINT: Use `--ntasks-per-node={ntasks}` instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You set `--ntasks=4` in your SLURM bash script, but this variable is not supported. HINT: Use `--ntasks-per-node=4` instead."
     ]
    }
   ],
   "source": [
    "training_module = MultiLabelLightningModule(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    learning_rate=learning_rate,\n",
    "    num_labels=num_labels,\n",
    "    scheduler=scheduler,\n",
    "    optimizer=optimizer,\n",
    ")\n",
    "\n",
    "pl_trainer = Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stop_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8ea17c",
   "metadata": {},
   "source": [
    "## start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2dbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_trainer.fit(\n",
    "    training_module,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d11a9",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_trainer.test(\n",
    "    model=training_module,\n",
    "    dataloaders=test_loader,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
