{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a307bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import timm\n",
    "import torch\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0232ebe8-c574-4fd7-8e6d-be20e2f7286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/taheeraa/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/cluster/home/taheeraa/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the directory containing the notebook and the src folder\n",
    "notebook_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add the src directory to sys.path\n",
    "src_dir = os.path.join(project_dir, 'src')\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from data import ChestXray14Dataset, build_transform_classification\n",
    "from trainers import MultiLabelLightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4bbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_labels = '/cluster/home/taheeraa/code/BenchmarkTransformers/dataset'\n",
    "file_path_train = path_to_labels + '/Xray14_train_official.txt'\n",
    "file_path_val = path_to_labels + '/Xray14_val_official.txt'\n",
    "file_path_test = path_to_labels + '/Xray14_test_official.txt'\n",
    "checkpoint_path = '/cluster/home/taheeraa/code/BenchmarkTransformers/Models/Classification/ChestXray14/swin_base_simmim/swin_base_simmim_run_0.pth.tar'\n",
    "\n",
    "data_path = '/cluster/home/taheeraa/datasets/chestxray-14'\n",
    "images_path = data_path + '/images'\n",
    "\n",
    "num_workers = 4\n",
    "pin_memory = False\n",
    "\n",
    "num_labels = 14\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "\n",
    "labels = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Effusion\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Hernia\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c66bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = build_transform_classification(\n",
    "    normalize=\"chestx-ray\", mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9ecc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ChestXray14Dataset(images_path=images_path, file_path=file_path_test,\n",
    "                                  augment=test_transforms, num_class=num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93975449-e8d1-4e50-99e4-61f6c13ca6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cd0f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/taheeraa/.local/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(\n",
    "            'swin_base_patch4_window7_224', num_classes=num_labels)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4be44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_module = MultiLabelLightningModule(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        learning_rate=learning_rate,\n",
    "        num_labels=num_labels,\n",
    "        labels=labels,\n",
    "        optimizer_func=optimizer,\n",
    "        scheduler_func=scheduler,\n",
    "        model_ckpts_folder='model_ckpts_folder',\n",
    "        model_name='swin',\n",
    "        experiment_name='eval',\n",
    "        img_size=224,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "343c062d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): BasicLayer(\n",
       "      dim=128, input_resolution=(56, 56), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(56, 56), dim=128\n",
       "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=256, input_resolution=(28, 28), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0-1): 2 x SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(28, 28), dim=256\n",
       "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=512, input_resolution=(14, 14), depth=18\n",
       "      (blocks): ModuleList(\n",
       "        (0-17): 18 x SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(14, 14), dim=512\n",
       "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=1024, input_resolution=(7, 7), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0-1): 2 x SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Linear(in_features=1024, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "ckpt_state_dict = checkpoint['state_dict']\n",
    "incompatiable_keys = training_module.load_state_dict(ckpt_state_dict, strict=False)\n",
    "model.load_state_dict(ckpt_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e69c4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659a3219ebce44baa80e77718dc88e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1948736827005632, 'f1': 0.062350154606974684, 'f1_micro': 0.2512708240095526, 'auroc': 0.41177231178153306}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "            Test metric                       DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "            test_auroc                     0.4118366837501526\n",
      "   test_auroc_atelectasis_epoch            0.6233771443367004\n",
      "   test_auroc_cardiomegaly_epoch           0.3357979357242584\n",
      "  test_auroc_consolidation_epoch            0.513145387172699\n",
      "      test_auroc_edema_epoch               0.3694961667060852\n",
      "     test_auroc_effusion_epoch             0.6794830560684204\n",
      "    test_auroc_emphysema_epoch             0.33530178666114807\n",
      "     test_auroc_fibrosis_epoch             0.24285291135311127\n",
      "      test_auroc_hernia_epoch              0.04066082835197449\n",
      "   test_auroc_infiltration_epoch           0.6077394485473633\n",
      "       test_auroc_mass_epoch               0.4172115623950958\n",
      "         test_auroc_micro                  0.8511410355567932\n",
      "      test_auroc_nodule_epoch              0.4501868784427643\n",
      "test_auroc_pleural_thickening_epoch        0.40677133202552795\n",
      "    test_auroc_pneumonia_epoch             0.28763893246650696\n",
      "   test_auroc_pneumothorax_epoch           0.4560508728027344\n",
      "              test_f1                      0.06235993653535843\n",
      "           test_f1_micro                   0.2513103187084198\n",
      "             test_loss                     0.19490039348602295\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Test Results: [{'test_auroc_atelectasis_epoch': 0.6233771443367004, 'test_auroc_cardiomegaly_epoch': 0.3357979357242584, 'test_auroc_effusion_epoch': 0.6794830560684204, 'test_auroc_infiltration_epoch': 0.6077394485473633, 'test_auroc_mass_epoch': 0.4172115623950958, 'test_auroc_nodule_epoch': 0.4501868784427643, 'test_auroc_pneumonia_epoch': 0.28763893246650696, 'test_auroc_pneumothorax_epoch': 0.4560508728027344, 'test_auroc_consolidation_epoch': 0.513145387172699, 'test_auroc_edema_epoch': 0.3694961667060852, 'test_auroc_emphysema_epoch': 0.33530178666114807, 'test_auroc_fibrosis_epoch': 0.24285291135311127, 'test_auroc_pleural_thickening_epoch': 0.40677133202552795, 'test_auroc_hernia_epoch': 0.04066082835197449, 'test_loss': 0.19490039348602295, 'test_f1': 0.06235993653535843, 'test_f1_micro': 0.2513103187084198, 'test_auroc': 0.4118366837501526, 'test_auroc_micro': 0.8511410355567932}]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pl_trainer = Trainer()\n",
    "\n",
    "results = pl_trainer.test(\n",
    "    model=training_module,\n",
    "    dataloaders=test_loader,\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Test Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
